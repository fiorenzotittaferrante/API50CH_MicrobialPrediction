{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81504c3e-a696-4851-a16d-2bd2475470a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Compute genes coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21be6547-b57f-4407-b143-247b4d977800",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, time, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('Code/')\n",
    "from utility import clean_ds_store\n",
    "\n",
    "clean_ds_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ddf56a-5547-4d85-9a1a-8ece443d7e98",
   "metadata": {},
   "source": [
    "Please pay attention to the following facts:\n",
    " * Not all genomes have the \"product\" attribute;\n",
    " * Not all strains present in the dataset have the corresponding .gff file in the gff folder;\n",
    " * There are some special cases such as 1150460.13.fna. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48231f89-fdb3-4f9d-9a29-337d6ebe13b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_file(file_name):\n",
    "    \"\"\"\n",
    "        Obtain the path of a .gff file.\n",
    "    \"\"\"\n",
    "        \n",
    "    folder_paths = ['Data/BacDive/gff/Patric/', 'Data/BacDive/gff/ncbi/Decompress/']\n",
    "\n",
    "    for folder_path in folder_paths:\n",
    "        for file in os.listdir(folder_path):\n",
    "            if file.startswith(file_name):\n",
    "                return os.path.join(folder_path, file)\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "def get_files_name():   \n",
    "    \"\"\"\n",
    "        Obtain the names of each .wri file.\n",
    "    \"\"\"\n",
    "    \n",
    "    filemap = dict()\n",
    "    files = [f for f in os.listdir('Data/BacDive/AFLP_perl') if os.path.isfile('Data/BacDive/AFLP_perl/'+f)]\n",
    "    \n",
    "    for f in files:\n",
    "        if f == '.DS_Store':\n",
    "            continue\n",
    "        \n",
    "        if 'GCA' in f:\n",
    "            filemap[f[:f.index('.')]] = f\n",
    "        else:\n",
    "            filemap[f.replace('.wri','')] = f\n",
    "            \n",
    "    return filemap\n",
    "\n",
    "\n",
    "\n",
    "def get_genomes(file_path):\n",
    "    \"\"\"\n",
    "        Given the path of a .wri file, returns a dataframe of each genomes of the strain.\n",
    "    \"\"\"\n",
    "    \n",
    "    column_names = ['Sequence', 'Database', 'type', \"5'\", \"3'\", 'idk', 'helix', 'idk2', 'info']\n",
    "    genome = pd.read_csv(file_path, sep='\\t', comment='#', header=None, names=column_names)\n",
    "    genome = genome[genome['type'] == 'CDS']\n",
    "    \n",
    "    tmp = genome['info'].str.split(';', expand=True)        \n",
    "    ids = tmp.apply(lambda x: next((val.split('=')[1] for val in x if 'ID=' in val), None), axis=1).to_frame()\n",
    "    products = tmp.apply(lambda x: next((val.split('=')[1] for val in x if 'product=' in val), \"N/A\") if any('product=' in val for val in x if isinstance(val, str)) else \"N/A\", axis=1).to_frame()\n",
    "    locus_tags = tmp.apply(lambda x: next((val.split('=')[1] for val in x if 'locus_tag=' in val), \"N/A\") if any('locus_tag=' in val for val in x if isinstance(val, str)) else \"N/A\", axis=1).to_frame()\n",
    "    \n",
    "    tmp = pd.concat([ids, products, locus_tags], axis=1)\n",
    "    tmp.columns = ['ID', 'Product', 'Locus tag']\n",
    "\n",
    "    genome.drop(columns='info', inplace=True)\n",
    "    genome = pd.concat([genome, tmp], axis=1)\n",
    "\n",
    "    return genome\n",
    "\n",
    "        \n",
    "    \n",
    "def get_genome_coverage(strain, filemap, aflp_min=50, aflp_max=500, feature_importances=None):   \n",
    "    \"\"\"\n",
    "        Calculate the coverage of the DNA for each strain, determine the location of the genes, \n",
    "        and assess whether they are completely, partially, or not covered by AFLP. \n",
    "        Then, calculate the importance of each gene based on the importance of the AFLP fragment where the gene is located.\n",
    "    \"\"\"\n",
    "    \n",
    "    DNA_coverages = dict()\n",
    "    DNA_importances = dict()\n",
    "    features = []\n",
    "    sequence = None\n",
    "    \n",
    "    genome_coverage = {\n",
    "        'Sequence': [],\n",
    "        'Sequence length': [],\n",
    "        'Start': [],\n",
    "        'End': [],\n",
    "        'Helix': [],\n",
    "        'Locus tag': [],\n",
    "        'Product': [],\n",
    "        'Type': [],\n",
    "        'Captured nucleotides': [],\n",
    "        'Coverage over genome length': [],\n",
    "        'Importance': [],\n",
    "    }\n",
    "        \n",
    "    # Open the strain.wri file and read the AFLP.\n",
    "    # This files contains only information about Sequences, coordinates of each fragments and their lengths.\n",
    "    if strain in filemap.keys():\n",
    "        with open('Data/BacDive/AFLP_perl/' + filemap[strain], 'r') as file:            \n",
    "            for line in file:\n",
    "                row = line.strip().split('\\t')\n",
    "\n",
    "                if len(row) == 9:\n",
    "                    frag_length = int(row[7])\n",
    "\n",
    "                    if (frag_length >= aflp_min) and (frag_length <= aflp_max):\n",
    "                        sequence = row[1]\n",
    "\n",
    "                        if sequence not in DNA_coverages:\n",
    "                            DNA_coverages[sequence] = [False for i in range(int(row[2]))]\n",
    "                            DNA_importances[sequence] = [0 for i in range(int(row[2]))]\n",
    "                        \n",
    "                        start = int(row[4])\n",
    "                        end = int(row[6])\n",
    "                        start = min(start, end)\n",
    "                        importance = feature_importances.loc[:, int(frag_length)].iloc[0]\n",
    "                        max_importance = max(DNA_importances[sequence][start:start+frag_length])                        \n",
    "\n",
    "                        if max_importance < importance:\n",
    "                            for i in range(start, start+frag_length):\n",
    "                                DNA_coverages[sequence][i] = True\n",
    "                                DNA_importances[sequence][i] = importance\n",
    "                        else:\n",
    "                            for i in range(start, start+frag_length):\n",
    "                                if DNA_importances[sequence][i] < importance:\n",
    "                                    DNA_coverages[sequence][i] = True\n",
    "                                    DNA_importances[sequence][i] = importance\n",
    "\n",
    "    \n",
    "    # Find the relative .gff file\n",
    "    # This files gives information about where the genes are.\n",
    "    path = find_file(file_name=strain)\n",
    "\n",
    "    if path is None:\n",
    "        return f'file {strain} not found.'\n",
    "    \n",
    "    genomes = get_genomes(path)\n",
    "        \n",
    "        \n",
    "    # sequence variable could be null due to .wri files which have sequence length less or greather then aflp_min and aflp_max.\n",
    "    if sequence is not None:\n",
    "        \n",
    "        for index, row in genomes.iterrows():\n",
    "\n",
    "            sequence_id = row.loc['Sequence']\n",
    "\n",
    "            if 'accn|' in sequence_id:\n",
    "                sequence_id = sequence_id[5::]\n",
    "\n",
    "            if sequence_id not in DNA_coverages.keys():\n",
    "                continue\n",
    "\n",
    "            sequence_length = len(DNA_coverages[sequence_id])\n",
    "            start = min(row.loc[\"5'\"] - 1, row.loc[\"3'\"] - 1)\n",
    "            end = max(row.loc[\"5'\"] - 1, row.loc[\"3'\"] - 1)\n",
    "            helix = row.loc['helix']            \n",
    "            product = row.loc['Product']\n",
    "            locus_tag = row.loc['Locus tag']            \n",
    "            genome_length = end - start\n",
    "\n",
    "            coverage = sum(DNA_coverages[sequence_id][start:end])\n",
    "            coverage2 = coverage / genome_length\n",
    "            genome_importance = np.mean(DNA_importances[sequence_id][start:end])\n",
    "\n",
    "            if coverage2 == 0:\n",
    "                classification = 'N'\n",
    "            elif coverage2 < 1:\n",
    "                classification = 'P'\n",
    "            else:\n",
    "                classification = 'T'                \n",
    "\n",
    "            genome_coverage['Sequence'].append(sequence_id)\n",
    "            genome_coverage['Sequence length'].append(sequence_length)\n",
    "            genome_coverage['Start'].append(start+1)\n",
    "            genome_coverage['End'].append(end+1)\n",
    "            genome_coverage['Helix'].append(helix)\n",
    "            genome_coverage['Locus tag'].append(locus_tag)\n",
    "            genome_coverage['Product'].append(product)\n",
    "            genome_coverage['Type'].append(classification)\n",
    "            genome_coverage['Captured nucleotides'].append(f'{coverage}/{genome_length}')\n",
    "            genome_coverage['Coverage over genome length'].append(coverage2)\n",
    "            genome_coverage['Importance'].append(genome_importance)\n",
    "                                \n",
    "    return genome_coverage\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f724b4c7-08ad-4cb6-8a16-cd7d5e5969ed",
   "metadata": {},
   "source": [
    "Execution of the programs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd3be673-f89e-4c4b-bc6f-ece664d6b542",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info: all result will be saved in Result/Coverages/\n",
      "\n",
      "Execution time for D-RIBose: 714.3540711402893 seconds.\n",
      "Execution time for N-AcetylGlucosamine: 773.6110079288483 seconds.\n",
      "Execution time for SALicin: 774.4000940322876 seconds.\n",
      "Execution time for D-CELlobiose: 757.5753448009491 seconds.\n",
      "Execution time for D-LACtose (bovine origin): 817.5171251296997 seconds.\n",
      "Execution time for D-MELibiose: 734.8802661895752 seconds.\n",
      "Execution time for D-SACcharose (sucrose): 734.4532721042633 seconds.\n",
      "Execution time for D-TREhalose: 753.1838119029999 seconds.\n",
      "Execution time for Methyl-Î±D-Glucopyranoside: 731.5646698474884 seconds.\n",
      "Execution time for D-TURanose: 794.804967880249 seconds.\n",
      "Execution time for D-MANnitol: 800.454832315445 seconds.\n",
      "Execution time for AMYgdalin: 719.4087779521942 seconds.\n",
      "Execution time for D-XYLose: 681.100686788559 seconds.\n",
      "Execution time for D-RAFfinose: 655.4781801700592 seconds.\n",
      "Execution time for GENtiobiose: 664.7213449478149 seconds.\n",
      "Execution time for L-ARAbinose: 664.133517742157 seconds.\n",
      "Execution time for ARButin: 695.7394371032715 seconds.\n",
      "Execution time for D-MaNnosE: 661.7486982345581 seconds.\n",
      "Execution time for D-GALactose: 663.1477451324463 seconds.\n",
      "Execution time for ESCulin ferric citrate: 662.7119591236115 seconds.\n",
      "Execution time for D-MALtose: 681.7303130626678 seconds.\n"
     ]
    }
   ],
   "source": [
    "coverages = None\n",
    "filemap = get_files_name()\n",
    "\n",
    "strains = filemap.keys()\n",
    "# strains = ['0'] # Local test\n",
    "# strains = ['1255.14']\n",
    "# strains = ['GCA_019655915'] # non presente nella cartella gff\n",
    "# strains = ['GCA_000008565'] # strain non presente nella cartella AFLP_perl\n",
    "\n",
    "print('Info: all result will be saved in Result/Coverages/\\n')\n",
    "\n",
    "\n",
    "if os.path.exists('./Result/feature_importances.xlsx'):\n",
    "    feature_importances = pd.read_excel('./Result/feature_importances.xlsx').set_index('Unnamed: 0').rename_axis(['Carbohydrates'])\n",
    "\n",
    "for carbohydrate, line in feature_importances.iterrows():\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    folder = f'Result/Coverages/Gene_Importances/{carbohydrate}/'\n",
    "    if not os.path.exists(f'Result/Coverages/Gene_Importances/{carbohydrate}/'):\n",
    "        os.makedirs(folder)\n",
    "    \n",
    "    for strain in strains:\n",
    "\n",
    "        genome_coverage = get_genome_coverage(strain, filemap, feature_importances=line.to_frame().T)\n",
    "        \n",
    "        if isinstance(genome_coverage, str):\n",
    "            # print(f'** Error: {genome_coverage}')\n",
    "            pass\n",
    "        else:\n",
    "            genome_coverage = pd.DataFrame(genome_coverage).sort_values(by='Importance', ascending=False)\n",
    "            genome_coverage.to_excel(os.path.join(folder, f'{strain}.xlsx'), index=False)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Execution time for {carbohydrate}: {end_time - start_time} seconds.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04686440-c103-45cb-b834-d036cb07ca4f",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f1fe55-a5a8-42f9-8687-bb5b651378af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coverages = None\n",
    "filemap = get_files_name()\n",
    "\n",
    "strains = filemap.keys()\n",
    "\n",
    "genome_coverage2 = get_genome_coverage('1423786.4', filemap, feature_importances=feature_importances)\n",
    "genome_coverage2 = pd.DataFrame(genome_coverage2).set_index('Sequence').sort_values(by='Coverage over genome length', ascending=False)\n",
    "display(genome_coverage2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
